{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "unlimited-decline",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Random\n",
    "using Distributions\n",
    "using CUDA\n",
    "using BenchmarkTools\n",
    "using BinomialGPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "little-intranet",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_SPINS = 26\n",
    "NUM_STATES = 10\n",
    "OMP_THREADS = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "promising-indiana",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26×26 Matrix{Float64}:\n",
       " -2.72238     4.69522     -1.46741   …   1.1384    -2.81682   -3.61539\n",
       " -4.03119     0.0482229   -1.41994       3.64753    3.91935    4.42098\n",
       "  2.46478    -4.25474      0.614348      3.47913    4.32819    1.98736\n",
       " -2.28121     1.17585      1.09892      -4.54873    3.48605    4.5098\n",
       " -3.98394    -3.57021      0.78932      -2.74622   -2.29096   -3.10407\n",
       " -0.830255   -0.892752     0.757896  …  -1.55618    0.405363  -0.279909\n",
       "  0.0157816  -2.47958     -0.902337     -0.608126  -4.27422    1.84045\n",
       " -4.33149    -2.82381      1.86028       1.78998   -1.57577    3.31655\n",
       "  2.78204     1.07209     -4.35964       1.41214    1.31462    0.907664\n",
       " -0.230495   -0.401193     2.19253       1.96024   -2.6724    -1.19597\n",
       " -0.802828    2.52374     -1.53606   …   2.27009    0.763966  -2.4742\n",
       " -1.48556     3.05474      4.71179       4.83306   -4.47457    3.20602\n",
       "  4.46694    -0.377336     2.88187       0.367546  -3.86627   -0.578989\n",
       "  4.54358     3.44772     -4.00524       3.17724    0.191716  -4.37777\n",
       " -3.25797    -4.05662     -1.26776      -3.04224   -4.48068   -4.6305\n",
       "  4.69874     4.2981       0.253448  …  -2.80557    1.28944    1.57254\n",
       " -1.71281     0.131226    -1.81895      -4.73073   -0.904974   2.31553\n",
       " -3.11682    -4.39225      0.085687      4.51798   -1.62984    0.6502\n",
       " -2.14897    -2.54482     -0.799249     -3.22685    0.525348  -2.32211\n",
       " -3.81665    -3.42336     -2.6399       -0.37369    2.44348    3.88971\n",
       "  3.2565      2.89909      4.81727   …  -3.78569    1.56984    0.496645\n",
       "  2.1995     -0.115478     0.658842      1.95094    0.986494  -2.28126\n",
       "  2.64367    -1.26635     -0.433814     -0.393864   3.78498   -1.28955\n",
       " -4.9528      0.0739204    2.00609       3.32715   -2.47181    3.03565\n",
       " -0.457893   -3.33142     -2.85962      -3.44105    3.44255    0.410532\n",
       " -0.929626    0.00584758  -3.06573   …   1.55913   -2.52508    4.58606"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_rand = rand(Uniform(-5,5),NUM_SPINS, NUM_SPINS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "changed-mayor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  8.42 KiB\n",
       "  allocs estimate:  10\n",
       "  --------------\n",
       "  minimum time:     4.015 μs (0.00% GC)\n",
       "  median time:      4.587 μs (0.00% GC)\n",
       "  mean time:        7.372 μs (7.32% GC)\n",
       "  maximum time:     903.651 μs (55.58% GC)\n",
       "  --------------\n",
       "  samples:          10000\n",
       "  evals/sample:     7"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@benchmark cu(rand(Uniform(-5,5),NUM_SPINS, NUM_SPINS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "equipped-bernard",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = Dict()\n",
    "for i in 0:NUM_SPINS\n",
    "    graph[(i, i)] = rand(Uniform(-5,5))\n",
    "    for j in i:NUM_SPINS\n",
    "        graph[(i, j)] = rand(Uniform(-5,5))\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "connected-watch",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Any, Any} with 378 entries:\n",
       "  (11, 17) => 1.75922\n",
       "  (8, 15)  => 1.09126\n",
       "  (16, 16) => -1.70168\n",
       "  (7, 18)  => 4.71631\n",
       "  (7, 8)   => 1.28611\n",
       "  (14, 15) => -2.54694\n",
       "  (7, 24)  => -1.54525\n",
       "  (1, 9)   => -2.54711\n",
       "  (15, 23) => -0.345505\n",
       "  (2, 26)  => -3.36633\n",
       "  (2, 17)  => 4.81567\n",
       "  (10, 17) => -2.46452\n",
       "  (10, 26) => 3.22568\n",
       "  (18, 18) => 1.44323\n",
       "  (18, 24) => 3.50805\n",
       "  (20, 26) => -3.95342\n",
       "  (17, 19) => -2.40701\n",
       "  (16, 18) => -1.93971\n",
       "  (16, 24) => 3.20406\n",
       "  (6, 23)  => 0.398331\n",
       "  (0, 26)  => 3.53226\n",
       "  (0, 17)  => 3.58651\n",
       "  (12, 21) => -2.49961\n",
       "  (9, 26)  => -1.80702\n",
       "  (9, 17)  => 1.51836\n",
       "  ⋮        => ⋮"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "median-aspect",
   "metadata": {},
   "outputs": [],
   "source": [
    "qubo = Dict()\n",
    "constant = 0\n",
    "\n",
    "for k in keys(graph)\n",
    "   qubo[k] = 0 \n",
    "end\n",
    "\n",
    "for i in 0:NUM_SPINS\n",
    "    qubo[(i,i)] = 2 * graph[(i,i)]\n",
    "    constant += graph[(i,i)]\n",
    "    \n",
    "    for j in 0:NUM_SPINS\n",
    "        if i!=j\n",
    "            low, high = sort!([i, j])\n",
    "            constant -= graph[(low,high)]*0.5\n",
    "            qubo[(i,i)] -= 2*graph[(low,high)]\n",
    "            qubo[(low,high)] += graph[(low,high)]*2\n",
    "        end\n",
    "    end\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "contrary-northwest",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Any, Any} with 378 entries:\n",
       "  (11, 17) => 7.03688\n",
       "  (8, 15)  => 4.36503\n",
       "  (16, 16) => 2.68409\n",
       "  (7, 18)  => 18.8652\n",
       "  (7, 8)   => 5.14446\n",
       "  (14, 15) => -10.1878\n",
       "  (7, 24)  => -6.18101\n",
       "  (1, 9)   => -10.1884\n",
       "  (15, 23) => -1.38202\n",
       "  (2, 26)  => -13.4653\n",
       "  (2, 17)  => 19.2627\n",
       "  (10, 17) => -9.85807\n",
       "  (10, 26) => 12.9027\n",
       "  (18, 18) => -21.5527\n",
       "  (18, 24) => 14.0322\n",
       "  (20, 26) => -15.8137\n",
       "  (17, 19) => -9.62805\n",
       "  (16, 18) => -7.75883\n",
       "  (16, 24) => 12.8162\n",
       "  (6, 23)  => 1.59332\n",
       "  (0, 26)  => 14.129\n",
       "  (0, 17)  => 14.3461\n",
       "  (12, 21) => -9.99846\n",
       "  (9, 26)  => -7.22808\n",
       "  (9, 17)  => 6.07345\n",
       "  ⋮        => ⋮"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qubo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "consolidated-ordering",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  348.564 s (1406147982 allocations: 56.38 GiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "32-element Vector{Float64}:\n",
       "   0.0\n",
       " -44.084180314968364\n",
       " -14.012573750590327\n",
       " -58.32324860101298\n",
       " -34.61669627695693\n",
       " -77.75803491438023\n",
       "  -9.88066960713104\n",
       " -53.248502780008636\n",
       " -45.798559096767235\n",
       " -72.27180397061437\n",
       " -25.78325623255217\n",
       " -52.48299564185359\n",
       " -85.34097945798413\n",
       "   ⋮\n",
       " -78.49211508105091\n",
       " -97.81487089009175\n",
       " -67.56889096267716\n",
       " -87.1181413071723\n",
       " -34.89711167352614\n",
       " -37.55177371899082\n",
       " -28.69461136076321\n",
       " -31.575767941682187\n",
       " -89.76581450187496\n",
       " -91.47763486979457\n",
       " -44.8147137686958\n",
       " -46.75302867206973"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@btime begin\n",
    "\n",
    "    NUM_SPINS = 20\n",
    "\n",
    "    graph = Dict()\n",
    "    for i in 0:NUM_SPINS\n",
    "        graph[(i, i)] = rand(Uniform(-5,5))\n",
    "        for j in i:NUM_SPINS\n",
    "            graph[(i, j)] = rand(Uniform(-5,5))\n",
    "        end\n",
    "    end\n",
    "\n",
    "    qubo = Dict()\n",
    "    constant = 0\n",
    "\n",
    "    for k in keys(graph)\n",
    "       qubo[k] = 0 \n",
    "    end\n",
    "\n",
    "    for i in 0:NUM_SPINS\n",
    "        qubo[(i,i)] = 2 * graph[(i,i)]\n",
    "        constant += graph[(i,i)]\n",
    "\n",
    "        for j in 0:NUM_SPINS\n",
    "            if i!=j\n",
    "                low, high = sort!([i, j])\n",
    "                constant -= graph[(low,high)]*0.5\n",
    "                qubo[(i,i)] -= 2*graph[(low,high)]\n",
    "                qubo[(low,high)] += graph[(low,high)]*2\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "\n",
    "    res = Vector{Float64}()\n",
    "#     res = Dict()\n",
    "    \n",
    "    N = NUM_SPINS\n",
    "    for (k, q) in enumerate(Iterators.product(fill(0:1,N)...))\n",
    "        F = 0\n",
    "        for i in 1:NUM_SPINS\n",
    "            F -= qubo[(i-1,i-1)]*q[i]  \n",
    "            for j in 1:NUM_SPINS\n",
    "                low, high = sort!([i-1, j-1])\n",
    "                F -= qubo[(low,high)]*q[i]*q[j]\n",
    "            end\n",
    "        end\n",
    "        append!(res, F) \n",
    "#         res[k] = F\n",
    "    end\n",
    "\n",
    "end\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "narrow-louisville",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32-element Vector{Pair{Int64, Float64}}:\n",
       " 14 => -110.87138265428621\n",
       " 22 => -97.81487089009175\n",
       " 30 => -91.47763486979457\n",
       " 29 => -89.76581450187496\n",
       " 24 => -87.1181413071723\n",
       " 13 => -85.34097945798413\n",
       " 21 => -78.49211508105091\n",
       "  6 => -77.75803491438023\n",
       " 20 => -76.86660466104473\n",
       " 10 => -72.27180397061437\n",
       " 23 => -67.56889096267716\n",
       "  4 => -58.32324860101298\n",
       " 19 => -56.374512639004536\n",
       "    ⋮\n",
       "  2 => -44.084180314968364\n",
       " 26 => -37.55177371899082\n",
       " 25 => -34.89711167352614\n",
       "  5 => -34.61669627695693\n",
       " 28 => -31.575767941682187\n",
       " 27 => -28.69461136076321\n",
       " 17 => -28.54913633696207\n",
       " 15 => -26.577076173352843\n",
       " 11 => -25.78325623255217\n",
       "  3 => -14.012573750590327\n",
       "  7 => -9.88066960713104\n",
       "  1 => 0.0"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resd = Dict(zip(1:size(res)[1],res))\n",
    "\n",
    "sort(collect(resd), by=x->x[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cheap-balloon",
   "metadata": {},
   "source": [
    "https://shinaoka.github.io/hpc_julia/docs/1dIsing.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "returning-presentation",
   "metadata": {},
   "outputs": [],
   "source": [
    "using BenchmarkTools, Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "amateur-camel",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: MersenneTwister not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: MersenneTwister not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[1]:18",
      " [2] eval",
      "   @ ./boot.jl:360 [inlined]",
      " [3] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base ./loading.jl:1094"
     ]
    }
   ],
   "source": [
    "function ising1d!(s, β, niters, rng)\n",
    "    n = length(s)\n",
    "    min_h = -2\n",
    "    max_h = 2\n",
    "    prob = [1/(1+exp(-2*β*h)) for h in min_h:max_h]\n",
    "    #prob_f(h) = 1/(1+exp(-2*β*h))\n",
    "    for iter in 1:niters, i in 1:n\n",
    "        sl = s[ifelse(i == 1, n, i-1)]\n",
    "        sr = s[ifelse(i == n, 1, i+1)]\n",
    "        # h = -2, 0, 2\n",
    "        h = sl + sr\n",
    "        s[i] = ifelse(rand(rng) < prob[h-min_h+1], +1, -1)\n",
    "        #s[i] = ifelse(rand(rng) < prob_f(h), +1, -1)\n",
    "    end\n",
    "end\n",
    "\n",
    "num_spins = 100\n",
    "rng = MersenneTwister(4649)\n",
    "s0 = rand(rng, Int8[-1, 1], num_spins)\n",
    "β = 10.0\n",
    "niters = 10^3\n",
    "\n",
    "s = copy(s0)\n",
    "\n",
    "# Run once to compile the function\n",
    "ising1d!(s, β, niters, rng)\n",
    "\n",
    "@time ising1d!(s, β, niters, rng)\n",
    "@benchmark ising1d!(s, β, niters, rng) setup=(s = copy(s0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "induced-acrylic",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "TypeError: in typeassert, expected Vector{Float64}, got a value of type Vector{StepRangeLen{Float64, Base.TwicePrecision{Float64}, Base.TwicePrecision{Float64}}}",
     "output_type": "error",
     "traceback": [
      "TypeError: in typeassert, expected Vector{Float64}, got a value of type Vector{StepRangeLen{Float64, Base.TwicePrecision{Float64}, Base.TwicePrecision{Float64}}}",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[6]:59",
      " [2] eval",
      "   @ ./boot.jl:360 [inlined]",
      " [3] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base ./loading.jl:1094"
     ]
    }
   ],
   "source": [
    "def ising_to_qubo(ham):\n",
    "    qubo = numpy.zeros(ham.shape)\n",
    "    constant = 0\n",
    "    for i in range(qubo.shape[0]):\n",
    "        qubo[i, i] = 2 * ham[i, i]\n",
    "        constant +=  ham[i, i]\n",
    "        for j in range(qubo.shape[0]):\n",
    "            if i != j:\n",
    "                low, high = sorted((i, j))\n",
    "                constant -= ham[low, high] * 0.5\n",
    "                qubo[i, i] -= 2 * ham[low, high]\n",
    "                qubo[low, high] += ham[low, high] * 2\n",
    "    return qubo, constant\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "different-postage",
   "metadata": {},
   "source": [
    "https://www.tensors.net/exact-diagonalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "upper-detective",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Pkg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "surprised-cabinet",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m `~/Workspace/Repo/Code/SpinGlassExhaustive.jl/Project.toml`\n",
      " \u001b[90m [7d9fca2a] \u001b[39m\u001b[92m+ Arpack v0.4.0\u001b[39m\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/Workspace/Repo/Code/SpinGlassExhaustive.jl/Manifest.toml`\n"
     ]
    }
   ],
   "source": [
    "Pkg.add(\"Arpack\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "filled-milton",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensordot"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "doApplyHam(psiIn,hloc,N,usePBC)\n",
    "------------------------\n",
    "by Glen Evenbly (c) for www.tensors.net, (v1.2) - last modified 06/2020\n",
    "------------------------\n",
    "Applies local Hamiltonian (given as sum of nearest neighbor terms 'hloc')\n",
    "to input state 'psiIn'. Number of lattice sites specified as 'N' while\n",
    "'usePBC' determines whether open or periodic boundaries are used.\n",
    "\"\"\"\n",
    "function doApplyHam(psiIn,hloc,N,usePBC)\n",
    "\n",
    "  d = size(hloc,1);\n",
    "  psiOut = zeros(d^N,1);\n",
    "  for k = 1:N-1\n",
    "    # apply local Hamiltonian terms to sites [k,k+1]\n",
    "    cont_inds = [[2],[2]];\n",
    "    psi_temp = tensordot(reshape(hloc,d^2,d^2),\n",
    "      reshape(psiIn,d^(k-1), d^2, d^(N-1-k)),cont_inds);\n",
    "    psiOut = psiOut + reshape(permutedims(psi_temp,[2,1,3]),d^N);\n",
    "  end\n",
    "\n",
    "  if usePBC\n",
    "    # apply periodic term\n",
    "    cont_inds = [[3,4],[3,1]];\n",
    "    psi_temp = tensordot(reshape(hloc,d,d,d,d),\n",
    "      reshape(psiIn,d, d^(N-2), d),cont_inds);\n",
    "    psiOut = psiOut + reshape(permutedims(psi_temp,[2,3,1]),d^N);\n",
    "  end\n",
    "\n",
    "  return psiOut\n",
    "end\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "tensordot(A,B,cont_inds):\n",
    "Function for taking the produce of two tensors A and B, designed to mimic the\n",
    "numpy tensordot. Input `cont_inds = [A_axes,B_axes]` where `A_axes` and\n",
    "`B_axes` are vectors describing the indices to be contracted, e.g. set\n",
    "cont_inds = [[2],[1]] to contract the 2nd index of A with the 1st index of B.\n",
    "\"\"\"\n",
    "function tensordot(A, B, cont_inds)\n",
    "\n",
    "  A_free = deleteat!(collect(1:ndims(A)), sort(cont_inds[1]))\n",
    "  B_free = deleteat!(collect(1:ndims(B)), sort(cont_inds[2]))\n",
    "  A_perm = vcat(A_free, cont_inds[1])\n",
    "  B_perm = vcat(cont_inds[2], B_free)\n",
    "\n",
    "  return reshape(\n",
    "    reshape(\n",
    "      permutedims(A, A_perm),\n",
    "      prod(size(A)[A_free]),\n",
    "      prod(size(A)[cont_inds[1]]),\n",
    "    ) * reshape(\n",
    "      permutedims(B, B_perm),\n",
    "      prod(size(B)[cont_inds[2]]),\n",
    "      prod(size(B)[B_free]),\n",
    "    ),\n",
    "    (size(A)[A_free]..., size(B)[B_free]...),\n",
    "  )\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "placed-petite",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ncon_check_inputs"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    ncon(tensor_list, connect_list_in; con_order=[], check_network=true)\n",
    "------------------------\n",
    "    by Glen Evenbly (c) for www.tensors.net, (v1.2) - last modified 6/2020\n",
    "------------------------\n",
    "Network CONtractor. Input is an array of tensors 'tensor_list' and an array of\n",
    "vectors 'connect_list_in',  with each vector labelling the indices of the\n",
    "corresponding tensor. Labels should be  positive integers for contracted indices\n",
    "and negative integers for free indices. Optional input 'con_order'  can be used\n",
    "to specify order of index contractions (otherwise defaults to ascending order of\n",
    "the positive indices). Checking of the consistancy of the input network can be\n",
    "disabled for slightly faster operation.\n",
    "\n",
    "Further information can be found at: https://arxiv.org/abs/1402.0939\n",
    "\"\"\"\n",
    "function ncon(\n",
    "  tensor_list,\n",
    "  connect_list_in;\n",
    "  con_order = [],\n",
    "  check_network = true,\n",
    ")\n",
    "\n",
    "  # copy original list to avoid destroying\n",
    "  connect_list = deepcopy(connect_list_in)\n",
    "\n",
    "  # put inputs into an array if necessary\n",
    "  if (tensor_list[1] isa Real) | (tensor_list[1] isa Complex)\n",
    "    tensor_list = Any[tensor_list]\n",
    "  end\n",
    "  if !(connect_list[1] isa Array)\n",
    "    connect_list = Any[connect_list]\n",
    "  end\n",
    "\n",
    "  # generate contraction order if necessary\n",
    "  flat_connect = vcat(connect_list...)\n",
    "  if isempty(con_order)\n",
    "    con_order = sort(unique(flat_connect[flat_connect.>0]))\n",
    "  end\n",
    "\n",
    "  # check inputs if enabled\n",
    "  if check_network\n",
    "    dims_list = Array{Any,1}(undef, length(tensor_list))\n",
    "    for ik = 1:length(tensor_list)\n",
    "      dims_list[ik] = [size(tensor_list[ik])...]\n",
    "    end\n",
    "    ncon_check_inputs(connect_list, flat_connect, dims_list, con_order)\n",
    "  end\n",
    "\n",
    "  # do all partial traces\n",
    "  for ip = 1:length(connect_list)\n",
    "    num_cont = length(connect_list[ip]) - length(unique(connect_list[ip]))\n",
    "    if num_cont > 0\n",
    "      tensor_list[ip], connect_list[ip], cont_label =\n",
    "        ncon_partial_trace(tensor_list[ip], connect_list[ip])\n",
    "      con_order = setdiff(con_order, cont_label)\n",
    "    end\n",
    "  end\n",
    "\n",
    "  # do all binary contractions\n",
    "  while !isempty(con_order)\n",
    "    # identify tensors to be contracted\n",
    "    cont_ind = con_order[1];\n",
    "    locs = [\n",
    "      ele\n",
    "      for\n",
    "      ele in collect(1:length(connect_list)) if\n",
    "      sum(connect_list[ele] .== cont_ind) > 0\n",
    "    ]\n",
    "\n",
    "    # do a binary contraction\n",
    "    cont_many = intersect(connect_list[locs[1]], connect_list[locs[2]])\n",
    "    A_cont = [findfirst(connect_list[locs[1]] .== x) for x in cont_many]\n",
    "    B_cont = [findfirst(connect_list[locs[2]] .== x) for x in cont_many]\n",
    "    A_free = deleteat!(collect(1:length(connect_list[locs[1]])), sort(A_cont))\n",
    "    B_free = deleteat!(collect(1:length(connect_list[locs[2]])), sort(B_cont))\n",
    "    push!(\n",
    "      tensor_list,\n",
    "      ncon_tensordot(\n",
    "        tensor_list[locs[1]],\n",
    "        tensor_list[locs[2]],\n",
    "        A_cont,\n",
    "        B_cont,\n",
    "      ),\n",
    "    )\n",
    "    push!(\n",
    "      connect_list,\n",
    "      vcat(connect_list[locs[1]][A_free], connect_list[locs[2]][B_free]),\n",
    "    )\n",
    "\n",
    "    # remove contracted tensors from list and update con_order\n",
    "    deleteat!(connect_list, locs)\n",
    "    deleteat!(tensor_list, locs)\n",
    "    con_order = setdiff(con_order, cont_many)\n",
    "  end\n",
    "\n",
    "  # do all outer products\n",
    "  while length(tensor_list) > 1\n",
    "    s1 = size(tensor_list[end-1])\n",
    "    s2 = size(tensor_list[end])\n",
    "    tensor_list[end-1] = reshape(\n",
    "      reshape(tensor_list[end-1], prod(s1)) *\n",
    "      reshape(tensor_list[end], 1, prod(s2)),\n",
    "      (s1..., s2...),\n",
    "    )\n",
    "    connect_list[end-1] = vcat(connect_list[end-1], connect_list[end])\n",
    "    deleteat!(connect_list, length(connect_list))\n",
    "    deleteat!(tensor_list, length(tensor_list))\n",
    "  end\n",
    "\n",
    "  # do final permutation\n",
    "  if length(connect_list[1]) > 0\n",
    "    return permutedims(tensor_list[1], sortperm(connect_list[1], by = abs))\n",
    "  else\n",
    "    return tensor_list[1][1]\n",
    "  end\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "ncon_tensordot: contracts a pair of tensors via matrix multiplication,\n",
    "similar to the Numpy function of the same name\n",
    "\"\"\"\n",
    "function ncon_tensordot(A, B, A_cont, B_cont)\n",
    "\n",
    "  A_free = deleteat!(collect(1:ndims(A)), sort(A_cont))\n",
    "  B_free = deleteat!(collect(1:ndims(B)), sort(B_cont))\n",
    "  A_perm = vcat(A_free, A_cont)\n",
    "  B_perm = vcat(B_cont, B_free)\n",
    "\n",
    "  return reshape(\n",
    "    reshape(\n",
    "      permutedims(A, A_perm),\n",
    "      prod(size(A)[A_free]),\n",
    "      prod(size(A)[A_cont]),\n",
    "    ) * reshape(\n",
    "      permutedims(B, B_perm),\n",
    "      prod(size(B)[B_cont]),\n",
    "      prod(size(B)[B_free]),\n",
    "    ),\n",
    "    (size(A)[A_free]..., size(B)[B_free]...),\n",
    "  )\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "ncon_partial_trace: partial trace on tensor A over repeated labels in A_label\n",
    "\"\"\"\n",
    "function ncon_partial_trace(A, A_label)\n",
    "\n",
    "  num_cont = length(A_label) - length(unique(A_label))\n",
    "  if num_cont > 0\n",
    "    dup_list = []\n",
    "    for ele in unique(A_label)\n",
    "      if sum(A_label .== ele) > 1\n",
    "        dup_list = vcat(dup_list, findall(A_label .== ele))\n",
    "      end\n",
    "    end\n",
    "\n",
    "    cont_ind =\n",
    "      reshape(permutedims(reshape(dup_list, 2, num_cont), [2, 1]), 2 * num_cont)\n",
    "    free_ind = deleteat!(collect(1:length(A_label)), sort(dup_list))\n",
    "    cont_dim = prod(size(A)[cont_ind[1:num_cont]])\n",
    "    free_dim = size(A)[free_ind]\n",
    "\n",
    "    cont_label = unique(A_label[cont_ind])\n",
    "    B = zeros(prod(free_dim))\n",
    "    perm_tot = [free_ind; cont_ind]\n",
    "\n",
    "    A_dims = size(A)\n",
    "    A = reshape(\n",
    "      permutedims(reshape(A[:], A_dims), vcat(free_ind, cont_ind)),\n",
    "      prod(free_dim),\n",
    "      cont_dim,\n",
    "      cont_dim,\n",
    "    )\n",
    "    for ip = 1:cont_dim\n",
    "      B = B + A[:, ip, ip]\n",
    "    end\n",
    "\n",
    "    return reshape(B, free_dim), deleteat!(A_label, sort(cont_ind)), cont_label\n",
    "  else\n",
    "    return A, A_label\n",
    "  end\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "ncon_check_inputs: check consistency of input tensor network\n",
    "\"\"\"\n",
    "function ncon_check_inputs(connect_list, flat_connect, dims_list, con_order)\n",
    "\n",
    "  pos_ind = flat_connect[flat_connect.>0]\n",
    "  neg_ind = flat_connect[flat_connect.<0]\n",
    "\n",
    "  # check that lengths of lists match\n",
    "  if length(dims_list) != length(connect_list)\n",
    "    e_str0 = \"NCON error: $(length(dims_list)) tensors given \";\n",
    "    error(e_str0,\"but $(length(connect_list)) index sublists given\")\n",
    "  end\n",
    "\n",
    "  # check that tensors have the right number of indices\n",
    "  for ik = 1:length(dims_list)\n",
    "    if length(dims_list[ik]) != length(connect_list[ik])\n",
    "      e_str0 = \"number of indices does not match number of labels on tensor \";\n",
    "      e_str1 = \"$(ik): $(length(dims_list[ik]))-indices \"\n",
    "      error(e_str0,e_str1,\"versus $(length(connect_list[ik]))-labels\")\n",
    "    end\n",
    "  end\n",
    "\n",
    "  # check that contraction order is valid\n",
    "  if !(sort(con_order) == sort(unique(pos_ind)))\n",
    "    error(\"NCON error: invalid contraction order\")\n",
    "  end\n",
    "\n",
    "  # check that negative indices are valid\n",
    "  for ind = -1:-1:-length(neg_ind)\n",
    "    if sum(neg_ind .== ind) == 0\n",
    "      error(\"NCON error: no index labelled $(ind)\")\n",
    "    elseif sum(neg_ind .== ind) > 1\n",
    "      error(\"NCON error: more than one index labelled $(ind)\")\n",
    "    end\n",
    "  end\n",
    "\n",
    "  # check that positive indices are valid and contracted tensor dimensions match\n",
    "  flat_dims = []\n",
    "  for ele in dims_list\n",
    "    flat_dims = vcat(flat_dims, ele)\n",
    "  end\n",
    "  for ind in unique(pos_ind)\n",
    "    if sum(pos_ind .== ind) == 1\n",
    "      error(\"NCON error: only one index labelled $(ind)\")\n",
    "    elseif sum(pos_ind .== ind) > 2\n",
    "      error(\"NCON error: more than two indices labelled $(ind)\")\n",
    "    end\n",
    "    cont_dims = flat_dims[flat_connect.==ind]\n",
    "    if cont_dims[1] != cont_dims[2]\n",
    "      e_str0 = \"dimension mismatch on index labelled $(ind): \"\n",
    "      error(e_str0,\"dim-$(cont_dims[1]) versus dim-$(cont_dims[2])\")\n",
    "    end\n",
    "  end\n",
    "\n",
    "  return true\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "numerous-property",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumSites: 18, Time: 8, Energy: -2.303508e+01, EnErr: 3.552714e-15 \n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "mainExactDiag.jl\n",
    "---------------------------------------------------------------------\n",
    "Script file for initializing exact diagonalization using the 'eigs' routine\n",
    "(based on Arpack) for a 1D quantum system\n",
    "\n",
    "by Glen Evenbly (c) for www.tensors.net, (v1.2) - last modified 06/2020\n",
    "\"\"\"\n",
    "\n",
    "using Printf, LinearAlgebra, LinearMaps, Arpack\n",
    "\n",
    "#### Your paths go here\n",
    "# include(\"ncon.jl\");\n",
    "# include(\"doApplyHam.jl\");\n",
    "\n",
    "##### Simulation parameters\n",
    "model = \"XX\" # select 'XX' or 'ising' models\n",
    "N = 18; # number of lattice sites\n",
    "usePBC = true; # use periodic or open boundaries\n",
    "numval = 1; # number of eigenstates to compute\n",
    "Nsites = 18\n",
    "##### Define Hamiltonian (quantum XX model)\n",
    "d = 2; # local dimension\n",
    "sX = [0 1; 1 0]; sY = [0 -im; im 0]; sZ = [1 0; 0 -1]; sI = [1 0; 0 1];\n",
    "if model == \"XX\"\n",
    "    hloc = reshape(real(kron(sX,sX) + kron(sY,sY)),2,2,2,2);\n",
    "    EnExact = -4/sin(pi/Nsites); # for PBC\n",
    "elseif model == \"ising\"\n",
    "    hloc = reshape(-kron(sX,sX) + 0.5*kron(sI,sZ) + 0.5*kron(sZ,sI),2,2,2,2);\n",
    "    EnExact = -2/sin(pi/(2*Nsites)); # for PBC\n",
    "end\n",
    "\n",
    "##### Recast the `doApplyHam` function as a LinearMap\n",
    "doApplyHamClosed = LinearMap(psiIn -> doApplyHam(psiIn,hloc,N,usePBC), d^N;\n",
    "  ismutating=false, issymmetric=true, ishermitian=true, isposdef=false)\n",
    "\n",
    "##### Diagonalize Hamiltonian with eigs\n",
    "diagtime = @elapsed Energy, psi = eigs(doApplyHamClosed; nev = numval,\n",
    "  tol = 1e-12, which=:SR, maxiter = 300);\n",
    "\n",
    "##### Check with exact energy\n",
    "EnErr = Energy[1] - EnExact; # should equal to zero\n",
    "@printf \"NumSites: %d, Time: %d, Energy: %e, EnErr: %e \\n\" Nsites diagtime Energy[1] EnErr\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "northern-ghost",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: CUDA not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: CUDA not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[23]:1",
      " [2] eval",
      "   @ ./boot.jl:360 [inlined]",
      " [3] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base ./loading.jl:1094"
     ]
    }
   ],
   "source": [
    "CUDA.limit(CUDA.LIMIT_DEV_RUNTIME_SYNC_DEPTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "raised-voice",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: b = Int32[1]\n",
      "└ @ Main In[24]:38\n",
      "┌ Info: c = Int32[0]\n",
      "└ @ Main In[24]:39\n"
     ]
    }
   ],
   "source": [
    "using CUDA\n",
    "\n",
    "function body(arr, my_shmem1, my_shmem2, i)\n",
    "    my_shmem1[i] = arr[i] + 1\n",
    "    my_shmem2[i] = arr[i]\n",
    "    sync_threads()\n",
    "    arr[i] = my_shmem1[i] - my_shmem2[i]\n",
    "end\n",
    "\n",
    "function static(arr :: CuDeviceArray{T}) where {T}\n",
    "    i = threadIdx().x\n",
    "    my_shmem1 = @cuStaticSharedMem(T, 1)\n",
    "    my_shmem2 = @cuStaticSharedMem(T, 1)\n",
    "    body(arr, my_shmem1, my_shmem2, i)\n",
    "    return nothing\n",
    "end\n",
    "\n",
    "function dynamic(arr :: CuDeviceArray{T}) where {T}\n",
    "    i = threadIdx().x\n",
    "    my_shmem1 = @cuDynamicSharedMem(T, 1)\n",
    "    my_shmem2 = @cuDynamicSharedMem(T, 1)\n",
    "    body(arr, my_shmem1, my_shmem2, i)\n",
    "    return nothing\n",
    "end\n",
    "\n",
    "N = 1\n",
    "T = Int32\n",
    "a = ones(T, 1)\n",
    "b = CuArray(a)\n",
    "c = CuArray(a)\n",
    "\n",
    "@cuda threads=N static(b)\n",
    "synchronize()\n",
    "\n",
    "@cuda threads=N shmem=sizeof(T) * 2 * N dynamic(c)\n",
    "synchronize()\n",
    "\n",
    "@info \"b = $b\"\n",
    "@info \"c = $c\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amended-effect",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Julia 1.6.0",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
